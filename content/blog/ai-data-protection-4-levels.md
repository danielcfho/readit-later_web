---
title: "AI「偷學」你的數據？6大頂級機構聯手提出數據保護4大分級體系"
date: "2025-07-20"
excerpt: "來自頂級科研團隊的全新視角，將數據在生成式AI時代的保護需求劃分為四個等級，從徹底不可用到可刪除權，為AI數據治理提供結構化框架。"
category: "AI"
tags: ["AI","數據保護","隱私","模型安全"]
author: "dchome"
featured: false
image: "https://images.unsplash.com/photo-1593642532973-d31b6557fa68?auto=compress&cs=tinysrgb&w=1260&h=750"
---

當我們將機密文檔或原創作品交給AI助手時，它們隨時可能成為訓練素材，默默改變著下一次推理的結果。傳統防火牆與加密手段，面對生成式AI的“流體數據”已顯捉襟見肘。最近，浙江大學、南洋理工、IBM、牛津大學等6大機構的研究者在論文《Rethinking Data Protection in the (Generative) Artificial Intelligence Era》[連結](http://arxiv.org/abs/2507.03034) 中，提出了一個涵蓋模型全生命週期的數據保護四級體系，助力各方在效用與控制之間找到平衡。

![AI數據保護四級體系](https://image.jiqizhixin.com/uploads/editor/9a40719e-06a1-448e-959b-c01a18569167/640.png)
研究團隊指出，最高級別的數據保護是“數據不可用”，即從源頭上阻絕任何AI訓練或推理的可能，即便數據洩露也毫無價值。稍弱一檔是“隱私保護”，通過差分隱私等技術隱藏個人或商業敏感信息，在保留數據可用性的前提下防止洩露。再往下是“數據可溯源”，強調記錄和追蹤數據的來源與使用軌跡，為審計與合規提供透明度。最後是“數據可刪除”，對應GDPR的可遺忘權，保證在許可撤回或數據過期時徹底消除影響。

![AI數據保護四級體系](https://image.jiqizhixin.com/uploads/editor/24b4b63c-1f0e-4b3f-87f9-d358f590ec17/640.png)
該分級體系不僅涵蓋訓練集、模型權重、系統提示和用戶輸入，還延伸到AI合成內容的版權與可控性。面對跨國數據流動和法規差異，這一框架有助於監管者與開發者釐清各自責任，推進更具前瞻性的數據治理方案。

在AI時代，理解並應用這四個保護等級，將成為技術與倫理共存的關鍵前提。只有明確了數據在不同環節的風險與可控方式，AI創新才能既高效又安全地造福社會。